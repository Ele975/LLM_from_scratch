{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6oNeTO3l6Ug1xSLH/pl+S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ele975/LLM_from_scratch/blob/main/Fine_tuning_for_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Description model fine-tuning for classification (spam detection)\n",
        "In general LLMs are not used for tasks such as spam detection, however this is for demonstration purposes with a simple task (they can be used if the spam detection mechanism should be very precise and the email are complex).\n",
        "\n",
        "After the pretraining where the model learns how to perdict next tokens in a coherent way, LLMs can be fine-tuned to perform required task such as classification, question answering, sentiment analysis, text generation, etc. The fine-tuning can be divided into:\n",
        "1. **fine-tuning for classification**: perform classification given an input such as spam detection, element recognition given images (tumors, object detection), text classification, etc. More specific than other fine-tuning since it is specialized in performing only the classification it saw only during the training phase\n",
        "\n",
        "2. **fine-tuning to follow instruction**: fine-tune model such that given some instructions (in form of prompts) in natural language it is able to understand and execute the required different tasks. E.g. \"**Translate in German** 'text to translate' \". Can perform different tasks"
      ],
      "metadata": {
        "id": "4vMQLrOkT2JP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data"
      ],
      "metadata": {
        "id": "YHMwozlPU3qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for tokenizer\n",
        "!pip install tiktoken\n",
        "\n",
        "# for weights loading\n",
        "!pip install tensorflow>=2.15.0\n",
        "!pip install tqdm>=4.66"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhi2OPmvkSoN",
        "outputId": "18c8c446-d2ef-4182-db90-fa1eadfbfea9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import urllib.request\n",
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "import json\n",
        "import psutil\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "l9NLRG6JUhg_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "Vu18ch7vPPqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pretraining functions"
      ],
      "metadata": {
        "id": "G8pK01xXTh74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"emb_dim\": 768,   # Embedding dimension\n",
        "    \"n_heads\": 12,  # Number of attention heads\n",
        "    \"n_layers\": 12,  # Number of layers\n",
        "    \"drop_rate\": 0.1,  # Dropout rate\n",
        "    \"qkv_bias\": False # Query-Key-Value bias\n",
        "}"
      ],
      "metadata": {
        "id": "-pz1qazmhUpk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BPE tokenizer"
      ],
      "metadata": {
        "id": "GbRrfLyn2Lnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "g0_fhqGRkhKp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self attention class with causal mask component and dropout"
      ],
      "metadata": {
        "id": "7Ko_iWuC-Lxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # mask has size context_length x context_length since we need to store the attention scores and attention weights for each token before the current one (lower triangular matrix)\n",
        "    self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length, diagonal=1)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    values = self.W_value(x)\n",
        "    queries = self.W_query(x)\n",
        "\n",
        "    # transpose last two dimensions of keys to enable matrix multiplication -> from (batch_size, tokens_nr, embedding_dim) to (batch_size, embedding_dim, )\n",
        "    attn_scores = queries @ keys.transpose(1,2)\n",
        "    # access the mask above saved as buffer -> not optimized during backpropagation but available during the forward pass (often with masks)\n",
        "    attn_scores.masked_fill(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SnlRQb5u-T9q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-head attention mechanism\n",
        "\n",
        "Multiple queries, keys and values in parallel permits to compute different attention weights and attention scores. The resulting context vectors are then concatenated."
      ],
      "metadata": {
        "id": "StFeRYjFc2VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionWrapper(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    # create the desired number of heads using the class above that generates a single causal attention head\n",
        "    self.heads = nn.ModuleList([CausalAttention(d_in, d_out, context_length, dropout, qkv_bias) for _ in range(num_heads)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    # head(x) call the forward method of the class CausalAttention and returns the context vectors for a single head\n",
        "    return torch.cat([head(x) for head in self.heads], dim=-1)"
      ],
      "metadata": {
        "id": "xMnfpcn2c8Pb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    # the inputs are multiplied by the matrices Q,K,V generating the reduced q,v,k which have the same dimension of the output context vector.\n",
        "    # For the parallel computation, q,v,k are split across the multiple heads, thus the dimension of q,v,k should be at least # heads\n",
        "    assert (d_out % num_heads == 0), \"d_out must be divisible by num_heads\"\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.out_proj = nn.Linear(d_out, d_out)\n",
        "\n",
        "    self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    # view = reshape from [b, num_tokens, d_in] to [b, num_tokens, self.num_heads, self.head_dim] -> dimensions of k,q,v for each head\n",
        "    keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "    # transpose in order to compute separately the results for each head, pass from [b, num_tokens, self.num_heads, self.head_dim] to [b, num_tokens, self.head_dim, self.num_heads]\n",
        "    keys = keys.transpose(1, 2)\n",
        "    queries = queries.transpose(1, 2)\n",
        "    values = values.transpose(1, 2)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(2,3)\n",
        "    # not always context_sizes correspond to num_tokens (last batch, last input can have less tokens), thus cut\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "    attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "    attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    # transpose again to pass from [b, num_tokens, self.head_dim, self.num_heads] to [b, self.head_dim, num_tokens, self.num_heads]\n",
        "    # permit to concanenate easier the results of the different heads\n",
        "    context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "    # combine head results\n",
        "    context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "\n",
        "    # raw concatenation is not enough for the models, thus this is used to refine the concatenation. Not mandatory but commonly used\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "    return context_vec\n"
      ],
      "metadata": {
        "id": "IPr69yP4cNYm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions to convert from tokens to tokens IDs and opposite (the model outputs are token IDs)"
      ],
      "metadata": {
        "id": "P1hMfooScnlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "  encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "  # insert batch dimension\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "  # remove batch dimension\n",
        "  flat = token_ids.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())"
      ],
      "metadata": {
        "id": "qn5Gi8IIct6a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT model architecture"
      ],
      "metadata": {
        "id": "oMBOcNOPc8Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "      mean = x.mean(dim=-1, keepdim=True)\n",
        "      var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "      norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "      return self.scale * norm_x + self.shift"
      ],
      "metadata": {
        "id": "7yWlU2CYpDSm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return 0.5 * x * (1 + torch.tanh(torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))))"
      ],
      "metadata": {
        "id": "LGHZeFWKuA3s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "                                GELU(),\n",
        "                                nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "wDzEEGZ9ubIR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(\n",
        "        d_in=cfg[\"emb_dim\"],\n",
        "        d_out=cfg[\"emb_dim\"],\n",
        "        context_length=cfg[\"context_length\"],\n",
        "        num_heads=cfg[\"n_heads\"],\n",
        "        dropout=cfg[\"drop_rate\"],\n",
        "        qkv_bias=cfg[\"qkv_bias\"]\n",
        "    )\n",
        "    self.ff = FeedForward(cfg)\n",
        "    # normalize the embedding dimension\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self, x):\n",
        "    # save input for attention shortcut\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "\n",
        "    # shortcut for FNN\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ff(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "uUMtqgofmr30"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "    *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "        cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "    )\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "6oTfYoC1vuWR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple version without text originality (used in the model traning)"
      ],
      "metadata": {
        "id": "IgGgjx98TDb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# idx -> input with size (batch, token ids)\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    # crops current context size to supported context size by the model -> if model supports size 5 and context size is 10, maintain last 5 tokens as context\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    # output of model is (batch, token, vocab), thus take last token\n",
        "    logits = logits[:, -1, :]\n",
        "    probas = torch.softmax(logits, dim=-1)\n",
        "    # get idx of the next token that will be part of the next input given to the model\n",
        "    idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "  return idx\n"
      ],
      "metadata": {
        "id": "hWotAydHf9bT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load pretrained GPT2 weights"
      ],
      "metadata": {
        "id": "a9zgu-rUf0fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get gpt_download.py\n",
        "\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/\"\n",
        "    \"LLMs-from-scratch/main/ch05/\"\n",
        "    \"01_main-chapter-code/gpt_download.py\"\n",
        ")\n",
        "filename = url.split('/')[-1]\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNTOtHbGsUes",
        "outputId": "dd2cfdc7-86b8-4c03-fd53-7d0b8cf82a63"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x7a993c8bac50>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load GPT-2 architecture settings and parameters"
      ],
      "metadata": {
        "id": "VeEKbSxttyul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrFd1PJUzELf",
        "outputId": "0783b2b5-d3bf-4820-d40e-7746aae5e354"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 106kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 660kiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 156kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [01:06<00:00, 7.43MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 7.88MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 382kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 373kiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All configurations for GPT-2 models (small, medium, large, xl)"
      ],
      "metadata": {
        "id": "RrBwdvQ1vD6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs = {\n",
        "  \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "  \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "  \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "  \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}"
      ],
      "metadata": {
        "id": "043ICH82vIzd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to check that left and right tensors have same shape (check if assignment of data is correct)"
      ],
      "metadata": {
        "id": "5Bk4jGCjwuDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        "  if left.shape != right.shape:\n",
        "    raise ValueError(f\"Shape mismatch. Left: {left.shape}, \" \"Right: {right.shape}\")\n",
        "  return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "Sks2FRY6w7wt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign loaded parameters to the new model with the new configuration. Complex function and based on some guessing since GPT used different names. It is possible to load the pretrained GPT model without manually assign all parameters, but this is for demonstration purpose (i.e. model = GPT2Model.from_pretrained(\"gpt2\"))"
      ],
      "metadata": {
        "id": "wIaw5i4pxAJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_weights_into_gpt(gpt, params):\n",
        "  # assign positional and token embeddings\n",
        "  gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "  gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "  # iteration over all transformer blocks\n",
        "  for b in range(len(params[\"blocks\"])):\n",
        "    # query, key and value components for self attention mechanism\n",
        "    # split concatenated weights for q,k,v into 3 components q_w, k_w, v_w, transpose and assign\n",
        "    q_w, k_w, v_w = np.split(\n",
        "        (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "        gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "    gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "        gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "    gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "        gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "    # same for biases\n",
        "    q_b, k_b, v_b = np.split(\n",
        "        (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "    gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "        gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "    gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "        gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "    gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "        gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "    # output projection\n",
        "    gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "        gpt.trf_blocks[b].att.out_proj.weight, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "        gpt.trf_blocks[b].att.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "    # feedforward nn\n",
        "    gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "    gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "    gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "    # layer normalization, where scale='g' for gain and shift='b' for bias\n",
        "    gpt.trf_blocks[b].norm1.scale = assign(\n",
        "        gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm1.shift = assign(\n",
        "        gpt.trf_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "    gpt.trf_blocks[b].norm2.scale = assign(\n",
        "        gpt.trf_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "    gpt.trf_blocks[b].norm2.shift = assign(\n",
        "        gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "  # final layer normalization and output head\n",
        "  gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "  gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "  gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ],
      "metadata": {
        "id": "p-4eY21-xGqY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning preprocessing"
      ],
      "metadata": {
        "id": "c_2oy-6lek1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download dataset for spam detection"
      ],
      "metadata": {
        "id": "cIgvJVqMYc_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "# name of downloaded file\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "# where the unzipped file is stored\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "# create path pointing to sms_spam_collection appending SMSSpamCollection to the path -> after the unzip the dataset will be called SMSSpamCollection.tsv\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "IOZ6BsM9YjUt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "  if data_file_path.exists():\n",
        "    print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "    return\n",
        "  # download file (write in zip_path the file read from url contained in 'response')\n",
        "  with urllib.request.urlopen(url) as response:\n",
        "    with open(zip_path, \"wb\") as out_file:\n",
        "        out_file.write(response.read())\n",
        "  # unzip file\n",
        "  with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "  # add .tsv file extension\n",
        "  original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "  # add .tsv extension\n",
        "  os.rename(original_file_path, data_file_path)\n",
        "  print(f\"File downloaded and saved as {data_file_path}\")\n"
      ],
      "metadata": {
        "id": "2VcteykjY0s7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRdoCLeSb8x0",
        "outputId": "fe1339a9-ee01-4769-ca68-926f2bbb0566"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load .tsv file in a dataframe"
      ],
      "metadata": {
        "id": "LJ4BqAoVcsqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# /t since it it tab-separated (TSV) to know how to separate columns\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"] )\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6C6Za6YWcyqC",
        "outputId": "717fcc0b-36b0-4bd2-8bf3-123b9d6bf2bf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3aa0c5b7-9fdb-4b27-9a95-3da38fdc788b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3aa0c5b7-9fdb-4b27-9a95-3da38fdc788b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3aa0c5b7-9fdb-4b27-9a95-3da38fdc788b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3aa0c5b7-9fdb-4b27-9a95-3da38fdc788b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c402c6e6-4071-48fd-b191-69ea26761bd5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c402c6e6-4071-48fd-b191-69ea26761bd5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c402c6e6-4071-48fd-b191-69ea26761bd5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_77c48197-b10a-40a9-b2af-f80eed1ecc9b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_77c48197-b10a-40a9-b2af-f80eed1ecc9b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0et9--zdPp1",
        "outputId": "f0baf30d-c716-45ea-d2d1-129f8848c039"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple dataset balancing since the two classes 'spam' and 'ham' have very different sizes -> done to avoid class bias and improve generalization (not performant with the small classes)"
      ],
      "metadata": {
        "id": "4D3tfHpslvUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        "  num_spam = df[df[\"Label\"] == 'spam'].shape[0]\n",
        "  # sample randomly num_spam number of ham data to balance the two classes. Ensure reproducibility with random_state\n",
        "  ham_subset = df[df[\"Label\"] == 'ham'].sample(num_spam, random_state=123)\n",
        "  # concatenate new column of the ham subset with all spam\n",
        "  balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "  return balanced_df"
      ],
      "metadata": {
        "id": "paj_M9cImLuu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3pzR57roimi",
        "outputId": "a241330e-db77-4cb9-f0a2-fd31218041de"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert labels into integers 0 and 1"
      ],
      "metadata": {
        "id": "imCPtGGMIj7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ],
      "metadata": {
        "id": "6wbcFAAlImme"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data in dataset randomly in training set (70%), validation set (10%), test set (20%)"
      ],
      "metadata": {
        "id": "wxu0wDbmJA2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "  # sample randomly data, since we take frac=1, we simply shuffle them. Drop old indices and reset them\n",
        "  df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "  # get indices of split\n",
        "  train_end = int(len(df) * train_frac)\n",
        "  validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "  train_df = df[:train_end]\n",
        "  validation_df = df[train_end:validation_end]\n",
        "  test_df = df[validation_end:]\n",
        "\n",
        "  return train_df, validation_df, test_df\n"
      ],
      "metadata": {
        "id": "fQner_naJJRS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
      ],
      "metadata": {
        "id": "fYIM2OE2V1aG"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save datasets as CSV"
      ],
      "metadata": {
        "id": "7XoMIrKaWLga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "id": "iTdrTPP6WNRk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create data loaders -> for the pretraining we had a sliding window that permit to had sentences of the same length, but in emails the lengths are different, thus:\n",
        "1. truncate all messages to the length of the shortest one -> cheaper but there is the possibility of information loss if the shortest message is really short\n",
        "\n",
        "2. add padding to all messages reaching the length of the longest one -> expensive but preserve information -> in this case we use this option with \"<|endoftext|>\" as padding token\n"
      ],
      "metadata": {
        "id": "0ohvFfZXXw-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpamDataset(Dataset):\n",
        "  def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "    self.data = pd.read_csv(csv_file)\n",
        "    self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
        "    if max_length is None:\n",
        "      self.max_length = self._longest_encoded_length()\n",
        "    else:\n",
        "      self.max_length = max_length\n",
        "    self.encoded_texts = [encoded_text[:self.max_length]for encoded_text in self.encoded_texts]\n",
        "    self.encoded_texts = [encoded_text + [pad_token_id] *(self.max_length - len(encoded_text))for encoded_text in self.encoded_texts]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    encoded = self.encoded_texts[index]\n",
        "    label = self.data.iloc[index][\"Label\"]\n",
        "    return (torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def _longest_encoded_length(self):\n",
        "    max_length = 0\n",
        "    for encoded_text in self.encoded_texts:\n",
        "      encoded_length = len(encoded_text)\n",
        "      if encoded_length > max_length:\n",
        "        max_length = encoded_length\n",
        "    return max_length\n"
      ],
      "metadata": {
        "id": "gfmqR9TboOpt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pad train, test and validation sets"
      ],
      "metadata": {
        "id": "KhCzmupO0mQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SpamDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "edEhm1oGrrUV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = SpamDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "GvQNoJut3NT8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SpamDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "93oL_Vqz3Os7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev3AyWdE0xoU",
        "outputId": "c508c935-7425-4438-d522-194b7773ea77"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate data loader -> each batch contains 8 input, where an input is an email text of 120 tokens and the label is 0 or 1 depending if spam or not"
      ],
      "metadata": {
        "id": "lyFMtRq_3giC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_workers = 0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0PHvz6l3hnF",
        "outputId": "a7f14c50-f634-4272-80d3-7f315517a0e3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a9a00f436d0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")"
      ],
      "metadata": {
        "id": "xRjr85Ty3nRM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ],
      "metadata": {
        "id": "PTh7YtOe3k2f"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ],
      "metadata": {
        "id": "G1baThSn3lx_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check batch sizes if correct"
      ],
      "metadata": {
        "id": "blnUTZYQ4Gsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_batch, target_batch in train_loader:\n",
        "  pass\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8xHbSxc4I4K",
        "outputId": "8b2b6dd1-8cb4-4a93-d70b-2b3b6c6c8db7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch dimensions: torch.Size([8, 120])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print total batches in each set"
      ],
      "metadata": {
        "id": "Rx095dOMKuUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep7HHTwnKwLD",
        "outputId": "3e0a479f-9c45-42dd-cafb-debaa76985f5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130 training batches\n",
            "19 validation batches\n",
            "38 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model setup"
      ],
      "metadata": {
        "id": "0F5HuwROe_J_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model initialization"
      ],
      "metadata": {
        "id": "YN0EN1moUwBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\""
      ],
      "metadata": {
        "id": "SOT3O2YcUydI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"drop_rate\": 0.0,\n",
        "    \"qkv_bias\": True\n",
        "}"
      ],
      "metadata": {
        "id": "9Sem6hreU1Ov"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}"
      ],
      "metadata": {
        "id": "QqLL9VcaU6yt"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
      ],
      "metadata": {
        "id": "tiQ2NUdtU_vp"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download weights into gpt-2 model"
      ],
      "metadata": {
        "id": "GuuUBtCJVLWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5eC2I_8VMzz",
        "outputId": "9b71fd8d-65f3-44c5-9bce-8cc9344765a2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if model outputs coherent text, thus the parameters has been loaded correctly"
      ],
      "metadata": {
        "id": "9s4pbaxAV6gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = \"Every effort moves you\"\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpLoS0YFV--Z",
        "outputId": "12e8af35-e7d6-43b7-ac4a-e0b61be935a7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification head\n",
        "Substitute the original output layer that maps to the vocabulary ('out_head') with a smaller output layer that maps to two classes only: 0 and 1 (not spam or spam). Without fine-tuning, with the new output layer the output of the model will be (batch_size, nr_tokens, vocab_dim), but the vocab_dim instead of being 50257 is now 2 (embedding dim) (for prediction of next token we take into consideration only the last token of the output).\n",
        "\n",
        "We freeze the model for the fine-tuning in order to not update the parameters -> keep the pre-trained weights intact and only train the new layers or the final layer to adapt the model to a new task or dataset"
      ],
      "metadata": {
        "id": "BHNA4TP-WETQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "rTh5uM_qWGZS"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change final layer. This one has requires_grad = True automatically, thus this will be the only layer updated during fine-tuning. However despite the fact this should be sufficient, by empirical experiments fine-tuning additional layers improve the performance of the model"
      ],
      "metadata": {
        "id": "JvjGqfKdYF9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "num_classes = 2\n",
        "\n",
        "model.out_head = torch.nn.Linear(\n",
        "    # = 768, output dimension of transformer blocks\n",
        "    in_features = BASE_CONFIG[\"emb_dim\"],\n",
        "    out_features = num_classes,\n",
        ")"
      ],
      "metadata": {
        "id": "ynOZjchuYHcR"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make trainable last transformer block and final LayerNorm"
      ],
      "metadata": {
        "id": "izxjQfBzZAOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "Jtz9MJ4PZfK4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider only last token of the output for the classification. Why? Given the implementation of the attention mask that permit each token to have information about all preceeding tokens in the sequence, the last one is the one with most information. Using the softmax on these two values for each input text we get the probability to be spam or not spam, and we take the highest one as the correct class"
      ],
      "metadata": {
        "id": "ZFk6jfjhcIDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implement evaluation utilities\n",
        "Compute classification loss and model accuracy (percentage of correct predictions)"
      ],
      "metadata": {
        "id": "gvrbmOmzr2IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "  model.eval()\n",
        "  correct_predictions, num_examples = 0, 0\n",
        "  if num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "      num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      input_batch = input_batch.to(device)\n",
        "      target_batch = target_batch.to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logits = model(input_batch)[:, -1, :]\n",
        "      predicted_labels = torch.argmax(logits, dim=-1)\n",
        "      num_examples += predicted_labels.shape[0]\n",
        "\n",
        "      correct_predictions += ((predicted_labels == target_batch).sum().item())\n",
        "    else:\n",
        "      break\n",
        "  return correct_predictions / num_examples"
      ],
      "metadata": {
        "id": "hDe0GO1Bsy-S"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function loss: cross-entropy for a single batch"
      ],
      "metadata": {
        "id": "v73MwIiQwpvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "  input_batch = input_batch.to(device)\n",
        "  target_batch = target_batch.to(device)\n",
        "  logits = model(input_batch)[:, -1, :]\n",
        "  loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "UT5wsEN2wrlw"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss for all batches"
      ],
      "metadata": {
        "id": "6kvhtEUtw3ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "  total_loss = 0.\n",
        "  if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "  elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        "  else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "  for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "    if i < num_batches:\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      total_loss += loss.item()\n",
        "    else:\n",
        "      break\n",
        "  return total_loss / num_batches"
      ],
      "metadata": {
        "id": "QFv8CLmLw5bF"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initial loss"
      ],
      "metadata": {
        "id": "G9NvGuHuxWOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "\n",
        "val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZoOun9UxXKU",
        "outputId": "65bc5f91-0fe5-445f-bc81-5c5ee59326a4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 2.183\n",
            "Validation loss: 2.583\n",
            "Test loss: 2.322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model fine-tuning and usage"
      ],
      "metadata": {
        "id": "LvlA9GHsYMZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device,num_epochs, eval_freq, eval_iter):\n",
        "  train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "  examples_seen, global_step = 0, -1\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for input_batch, target_batch in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      examples_seen += input_batch.shape[0]\n",
        "      global_step += 1\n",
        "\n",
        "      if global_step % eval_freq == 0:\n",
        "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "              f\"Train loss {train_loss:.3f}, \"\n",
        "              f\"Val loss {val_loss:.3f}\")\n",
        "\n",
        "    train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "    val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "\n",
        "    print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "    print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "    train_accs.append(train_accuracy)\n",
        "    val_accs.append(val_accuracy)\n",
        "  return train_losses, val_losses, train_accs, val_accs, examples_seen\n"
      ],
      "metadata": {
        "id": "BRZDmypE219M"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation: compute loss over training and evaluation sets ensuring model is in evaluation mode without dropout  "
      ],
      "metadata": {
        "id": "UcVW_1q1JGM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "  model.eval()\n",
        "  # not required in evaluation and save computational space\n",
        "  with torch.no_grad():\n",
        "    # compute loss for multiple batches to have more stable evaluation\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    # swap again to training mode for the training process in train_model_simple()\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ],
      "metadata": {
        "id": "4MFjp0QJGeoc"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model by taking a text snippet and passing to the model"
      ],
      "metadata": {
        "id": "ePvsVqp0v0ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start_context = text snippet for evaluation purposes\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "  model.eval()\n",
        "  # in the positional embedding weights the first shape is the context size\n",
        "  context_size = model.pos_emb.weight.shape[0]\n",
        "  encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "  with torch.no_grad():\n",
        "    # use the model in order to get the predicted next tokens starting from start_context\n",
        "    token_ids = generate_text_simple(model=model, idx=encoded,max_new_tokens=50, context_size=context_size)\n",
        "  decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "  print(decoded_text.replace(\"\\n\", \" \"))\n",
        "  model.train()"
      ],
      "metadata": {
        "id": "6yhf8ig7xvXE"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run fine-tuning computing the time needed"
      ],
      "metadata": {
        "id": "bI_Kw6udBrSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "num_epochs = 5"
      ],
      "metadata": {
        "id": "a7LV2lbFB9bh"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "        model, train_loader, val_loader, optimizer, device,\n",
        "        num_epochs=num_epochs, eval_freq=50,\n",
        "        eval_iter=5\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time)/60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E-Sgjn2A3WY",
        "outputId": "c8a782e5-c2aa-47fc-81c3-e844821933b5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
            "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
            "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
            "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
            "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
            "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
            "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
            "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
            "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
            "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
            "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training completed in 58.15 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "  fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "  # plot training and validation values with respect to epochs\n",
        "  ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "  ax1.plot(epochs_seen, val_values, label=f\"Validation {label}\")\n",
        "  ax1.set_xlabel(\"Epoch\")\n",
        "  ax1.set_ylabel(label.capitalize())\n",
        "  ax1.legend()\n",
        "\n",
        "  # create new x-axis on same plot that overlay x1 but without interfere\n",
        "  ax2 = ax1.twiny()\n",
        "  ax2.plot(examples_seen, train_values, alpha=0)\n",
        "  ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "  # adjust layout to avoid overlap between plot elements\n",
        "  fig.tight_layout()\n",
        "  # store plot\n",
        "  plt.savefig(f\"{label}-plot.pdf\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "dgUrbgGJEdsf"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot classification loss"
      ],
      "metadata": {
        "id": "dN5Uu_c2EaUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Pr4D1ShzdRfj",
        "outputId": "b5a45917-94eb-46fe-ddbd-25ad2f08323e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot classification accuracy"
      ],
      "metadata": {
        "id": "7gb8-rKnDQl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "o8HoG5W8DSMo",
        "outputId": "a300c6ca-95f9-4c46-ef83-5f8563de69b1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute accuracy of entire datasets"
      ],
      "metadata": {
        "id": "AV74-UoVvpdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)"
      ],
      "metadata": {
        "id": "qPCU52gevlq7"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UakE9UaLwORn",
        "outputId": "5cac1ca1-a7e1-458e-efd4-5021bca2a97c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 97.21%\n",
            "Validation accuracy: 97.32%\n",
            "Test accuracy: 95.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use model for email classification with new data"
      ],
      "metadata": {
        "id": "pVbkL1B7w_hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "  model.eval()\n",
        "  input_ids = tokenizer.encode(text)\n",
        "  # gives the maximum sequence length that can be processed by the model (the one chosen as maximum length for the fine-tuning)\n",
        "  supported_context_length = model.pos_emb.weight.shape[1]\n",
        "  # truncate text if needed\n",
        "  input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "  # add padding\n",
        "  input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "\n",
        "  input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # get last token with all information\n",
        "    logits = model(input_tensor)[:, -1, :]\n",
        "  # get value (0,1) associated with highest probability of last token\n",
        "  predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "  return \"spam\" if predicted_label == 1 else \"not spam\"\n"
      ],
      "metadata": {
        "id": "l3SThihxxDcU"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check prediction"
      ],
      "metadata": {
        "id": "veZgqr_Y09Gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "text_2 = (\n",
        "    \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        ")"
      ],
      "metadata": {
        "id": "vhcDhkI8yrKT"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classify_review(text_1, model, tokenizer, device, max_length= train_dataset.max_length))\n",
        "print(classify_review(text_2, model, tokenizer, device, max_length=train_dataset.max_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7EVH4thytLq",
        "outputId": "453b08dc-91ed-4adb-aa74-0fac275ba20a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n",
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model"
      ],
      "metadata": {
        "id": "v3LoCpFV062O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"review_classifier.pth\")"
      ],
      "metadata": {
        "id": "nzAWnEZC06hQ"
      },
      "execution_count": 68,
      "outputs": []
    }
  ]
}